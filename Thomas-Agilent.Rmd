---
title: "Microplastic fingerprinting"
output: 
  md_document:
    variant: markdown_github
---

```{r setup, include=FALSE}
knitr::opts_knit$set(root.dir = "C:/Users/huyng/OneDrive - Toronto Metropolitan University/Microplastic/Microplastic-Fingerprinting")
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(out.width='750px', dpi=200)
```

## Documentation

This repo is accompanying the publication: "Computational fingerprinting workflow for environmental source tracking of microplastic based on representative additives"

Demo of each ML algorithms is shown below.

## Data processing

You can include R code in the document as follows:

```{r class.source = 'fold-hide', echo = FALSE, message = FALSE, warning = FALSE}
# Loading Packages --------------------------------------------------------
library(ggplot2)
library(vegan)
library(readxl)
library(tidyverse)
library(dplyr)
library(data.table)
library(writexl)
library(tidyr)
library(grid)
library(gridExtra)
library(plotly)
library(stats)
library(FactoMineR)
library(factoextra)
library(compositions)
library(ggforce)
library(latticeExtra)
library(cluster)
library(cowplot)
'%notin%' <- Negate('%in%')
```

```{r class.source = 'fold-hide', echo = FALSE, message = FALSE, warning = FALSE}
# STEP 1.1: Data import --------------------------------------------

polymer <- readxl::read_xlsx(paste0(getwd(), "/TMU_Polymer_trainingsetA_Thomas_crookes.xlsx"), 
                             .name_repair = "minimal" # No name repair or checks, beyond basic existence,
                             )


group_columns <- function(df) {
  # Get the unique column names
  unique_names <- unique(names(df))
  
  # Initialize an empty list to store grouped column names
  grouped_columns <- list()
  
  # Loop through unique column names
  for (name in unique_names) {
    # Find columns with the same name
    matching_columns <- which(names(df) == name)
    
    # If there are duplicates, group them
    if (length(matching_columns) > 1) {
      grouped_columns[[name]] <- matching_columns
    }
  }
  
  return(grouped_columns)
}

# Create a list of columns with the same name (aka. replicates of the same measurement)
column_groups <- group_columns(polymer)

df_list <- list()
count <- 1
# For each element in the list, make a dataframe that contains wavenumber, sample_name and values
for (i in 1:length(column_groups)) {
  temp <- polymer[, c(1, column_groups[i][[1]])]
  for (j in 2:ncol(temp)) {
    colnames(temp)[j] <- paste0(colnames(temp)[j], "_rep", j-1)
  }
  
  temp <- temp %>% pivot_longer(cols = 2:ncol(.), names_to = "sample", values_to = "values")
  df_list[[count]] <- temp
  count <- count + 1
}

# Combine them all into big df
grand_df <- do.call(rbind, df_list) %>%
  mutate(polymer = ifelse(grepl("ULDPE", sample, ignore.case = TRUE), "ULDPE",
                          ifelse(grepl("LLDPE1", sample, ignore.case = TRUE), "LLDPE1",
                                 ifelse(grepl("LLDPE2", sample, ignore.case = TRUE), "LLDPE2",
                                        ifelse(grepl("LDPE1", sample,, ignore.case = TRUE), "LDPE1",
                                               ifelse(grepl("LDPE2", sample, ignore.case = TRUE), "LDPE2",
                                                      ifelse(grepl("MDPE", sample, ignore.case = TRUE), "MDPE",
                                                             ifelse(grepl("HDPE1", sample, ignore.case = TRUE), "HDPE1",
                                                                    ifelse(grepl("HDPE2", sample,ignore.case = TRUE), "HDPE2", 
                                                                           ifelse(grepl("PP", sample,ignore.case = TRUE), "PP", 
                                                                                  ifelse(grepl("PEST", sample,ignore.case = TRUE), "PEST", 
                                                                                         ifelse(grepl("PET1", sample,ignore.case = TRUE), "PET1", 
                                                                                                ifelse(grepl("PET2", sample,ignore.case = TRUE), "PET2", 
                                                                                                       ifelse(grepl("EVA", sample,ignore.case = TRUE), "EVA",
                                                                                                              ifelse(grepl("ABS", sample,ignore.case = TRUE), "ABS",
                                                                                                                     ifelse(grepl("EPS", sample,ignore.case = TRUE), "EPS",
                                                                                                                            ifelse(grepl("PS", sample,ignore.case = TRUE), "PS",
                                                                                                                                   ifelse(grepl("PA6", sample,ignore.case = TRUE), "PA6",
                                                                                                                                          ifelse(grepl("PA66", sample,ignore.case = TRUE), "PA66",
                                                                                                                                                 ifelse(grepl("PVC1", sample,ignore.case = TRUE), "PVC1",
                                                                                                                                                        ifelse(grepl("PVC2", sample, ignore.case = TRUE), "PVC2",
                                                                                                                                                               ifelse(grepl("CR", sample, ignore.case = TRUE), "CR", "CA")))))))))))))))))))))) %>%
  mutate(day =  ifelse(grepl("day 0", sample, ignore.case = TRUE), 0, 
                       ifelse(grepl("day 14", sample, ignore.case = TRUE), 14, 
                              ifelse(grepl("day 30", sample, ignore.case = TRUE), 30, 
                                     ifelse(grepl("day 7", sample, ignore.case = TRUE), 7, 
                                            ifelse(grepl("day 1", sample, ignore.case = TRUE), 1,
                                                   ifelse(grepl("day 21", sample, ignore.case = TRUE), 21, 3))))))) %>%
  pivot_wider(names_from = `Wavenumber (cm{ยน)`, values_from = values)
  
```

# Exploratory data analysis

### Differences in each polymer between Day 0 to Day 30

```{r , echo=FALSE, warning = FALSE, message=FALSE}
plotdat <- grand_df %>%
  pivot_longer(cols = 4:ncol(.), names_to = "Wavelength", values_to = "Values") %>%
  group_by(polymer, day, Wavelength) %>%
  summarise(across(Values, base::mean))

plotlist <- list()
for (i in unique(plotdat$polymer)) {
  subdf <- plotdat %>% filter(polymer %in% unique(plotdat$polymer)[i]) %>% mutate(day = factor(day, levels = unique(plotdat$day)))
  plotlist[[i]] <- ggplot(subdf, aes(x = Wavelength, y = Values)) +
    geom_point(aes(colour = day), size = 1) +
    labs(title = polymer,
         x = NULL,
         y = NULL) +  
    theme_minimal() + 
    theme(legend.position = "hidden") + 
    guides(colour = guide_legend(override.aes = list(size = 10)))
}

legend <- cowplot::get_legend(ggplot(subdf, aes(x = Wavelength, y = Values)) +
                                geom_point(aes(colour = day), size = 1) +
                                labs(title = polymer,
                                     x = NULL,
                                     y = NULL) +  
                                theme_minimal() + 
                                guides(colour = guide_legend(override.aes = list(size = 10))) +
                                theme(legend.position = "bottom"))

p <- gridExtra::grid.arrange(grobs= plotlist, ncol = 5,
                        top = legend, 
                        left = textGrob("Signal intensity", 
                                        rot = 90, gp = gpar(fontsize = 10)), 
                        bottom = textGrob("Wavenumber", gp = gpar(fontsize = 10)))

ggsave(filename = "plot.png", plot = p, width = 12, height = 10)

```

# Statistical fingerprinting

## PCA

(Update 3rd may 2024;) PCA of both zero and global minimum provides no distinctive clusters

```{r , echo=FALSE, warning = FALSE, message=FALSE}
# PCA
input <- grand_df %>% 
    filter(day == 14) 

res.pca <- FactoMineR::PCA(
  input %>%
    select(-c("sample", "day", "polymer")),
  scale.unit = FALSE,
  graph = FALSE)

# Scree plot
# fviz_screeplot(res.pca, ncp=10)

# Biplot
factoextra::fviz_pca_biplot(res.pca,  
                            geom = c("point", "text"),
                            label = "none", 
                            invisible = "var", 
                            repel = TRUE,
                            labelsize = 10, 
                            habillage = factor(input$polymer),
                            addEllipses = TRUE,
                            ellipse.level=0.95,
                            ggtheme = ggplot2::theme_minimal(base_size = 20),
                            title = "",
                            # xlim = c(-0.5, 0.5),
                            # ylim = c(-0.25, 0.2)
) + 
  guides(fill=guide_legend(ncol=5)) +
  # if has error "Too few points to calculate an ellipse"
  # ggforce::geom_mark_ellipse(aes(fill = Groups,
  #                                color = Groups),
  #                            label.buffer = unit(40, 'mm')) +
  theme(legend.position = 'bottom',
        panel.grid.minor.x = element_blank(),
        panel.grid.minor.y = element_blank()
  )
```

### Barplot of Top 10 Variable contributions to first n dimensions

```{r , echo=FALSE, warning = FALSE, message=FALSE}
# Variable contributions to first n dimensions
## To PC1
fviz_contrib(res.pca, choice = "var", axes = 1, top = 10)
## To PC2
fviz_contrib(res.pca, choice = "var", axes = 2, top = 10)

# Extract top 10 contribution to PC1
dim1 <- as.data.frame(res.pca$var$contrib) %>% arrange(desc(Dim.1))
top10 <- rownames(dim1[1:10,])

# Plot bar plot
plotdat <- icp_subcat %>% 
  select(c(Subcategory, top10)) %>%
  pivot_longer(cols = 2:ncol(.), names_to = "Features", values_to = "Values")

data_summary <- plotdat %>%
  group_by(Subcategory, Features) %>%
  summarise(mean = mean(Values), sd = sd(Values), .groups = 'drop')

ggplot(data = data_summary, aes(x = Subcategory, y = mean, fill = Features)) +
  geom_bar(stat = "identity", position = 'dodge') +
  geom_errorbar(aes(ymin = mean - sd,
                    ymax = mean + sd),
                position = position_dodge(width = 0.9), width = 0.25) +
  labs(x = "Plastic product group", y = "Normalized Concentration") + 
  theme_classic(base_size = 30) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r , echo=FALSE, warning = FALSE, message=FALSE}
# 3D PCa plot ===============================================================================
# FactoMineR_p <- FactoMineR::PCA(df_pca,
#                                 scale.unit = FALSE)
# 
# scores <- as.data.frame(FactoMineR_p$ind$coord[,1:3]) %>%
#   rownames_to_column(., var = "File")
# category <- sapply(scores$File, function(f) {
#   unique(gc_hplc_list[[1]]$Category[match(f, gc_hplc_list[[1]]$File)])
# })
# 
# # Add to scores data frame
# scores$Category <- as.factor(category)
# 
# rgl::plot3d(scores$Dim.1, scores$Dim.2, scores$Dim.3,
#        col = as.integer(scores$Category),
#        xlab = "PC1",
#        ylab = "PC2",
#        zlab = "PC3",
#        type = "p")
# 
# # Add legend
# rgl::legend3d("topright", legend = levels(scores$Category), col = 1:length(levels(scores$Category)), pch = 16)

# factoextra::fviz_screeplot(FactoMineR_p)
# factoextra::fviz_pca_biplot(FactoMineR_p,
#                             habillage = unique(gc_hplc_list[[1]]$File))
```


## HCA

If we filter unique compounds by File (compounds appear in at least 2 files), then all File in df in gc_hplc_list are the same. That's why here we used gc_hplc_list[[1]]

This exercise does not seems to affect the HCa. Keep in mind that for all 3 cases of data combinations: none of them has compounds that occur in all samples. NONE of THEM!!!!!

### Clustering of samples

(Update 3rd May 2024:) With zero and global minimum imputation, I saw that the two mixture was clustered within 2 out of 3 of its components (Woodbridge foam and new tire rubber)

```{r echo=FALSE, warning=FALSE, message=FALSE}
input <- grand_df %>% 
    filter(day == 0) 

hc_df <- input %>% select(-c("sample", "day", "polymer"))

## Dissimilarity Indices Calculated by vegan::vegdist()
hca_samp <- stats::hclust(vegan::vegdist(hc_df,
                                         method = "robust.aitchison")) # Since our data is continous -> canberra // manhattan // aitchison // robust.aitchison

plot(hca_samp,
     labels = input$polymer,
     hang = -1,
     main = "")
```

## K-means Clustering

```{r, echo=FALSE, warning = FALSE, message=FALSE}
tot.withinss <- list()
for (n_clus in 1:nrow(df_percentage)) {
  set.seed(round(runif(2:20, 0, 999)))
  km.out <- stats::kmeans(df_percentage, n_clus, nstart = 50)
  tot.withinss[[n_clus]] <- km.out$tot.withinss
  print(paste0("The number of centers is ", n_clus, " and total within-cluster sum of square is ", km.out$tot.withinss))
}

plot(df, col = (stats::kmeans(df, 171, nstart = 50)$cluster + 1) ,
     main = "K- Means Clustering Results with K = 2",
     xlab = "", ylab = "", pch = 20, cex = 2)


```

## UMAP clustering 

```{r, echo=FALSE, warning = FALSE, message=FALSE}
library(umap)

input <- grand_df %>%
  filter(day == 30)

features <- subset(input, select = -c(sample, day, polymer))

umap <- umap(features, n_components = 3,
             method = 'naive', 
             metric= "pearson2", # euclidean, manhattan, cosine, pearson, pearson2
             alpha = 0.0001, gamma = 0.0001)

layout <- cbind(data.frame(umap[["layout"]]), input$polymer)
umap_plot <- plot_ly(layout, x = ~X1, y = ~X2, z = ~X3, 
                     color = ~input$polymer) %>% 
  add_markers() %>%
  layout(scene = list(xaxis = list(title = 'x-axis'),
                      yaxis = list(title = 'y-axis'),
                      zaxis = list(title = 'z-axis')))

umap_plot
```
